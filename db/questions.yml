rounds:
  - number: 1
    questions:
      - text: "In what year did OpenAI first release the GPT-3 language model?"
        options: ["2019", "2021", "2020", "2022"]
        correct_index: 2
        points: 1
        time_limit: 20

      - text: "What does 'token' refer to in a language model?"
        options: ["A programming function", "A chunk of text the model reads", "A neural layer", "An API call"]
        correct_index: 1
        points: 1
        time_limit: 20

      - text: "Which practice helps reduce hallucinations in AI responses?"
        options: ["Adding vague prompts", "Increasing temperature", "Randomizing output", "Using clear and specific instructions"]
        correct_index: 3
        points: 1
        time_limit: 20

      - text: "What is the purpose of a model’s ‘context window’?"
        options: ["It defines how long the API runs", "It limits how much text the model can consider at once", "It controls model accuracy", "It measures latency"]
        correct_index: 1
        points: 1
        time_limit: 20

      - text: "What technique improves prompt effectiveness by including examples?"
        options: ["Few-shot prompting", "Prompt compression", "Token expansion", "Chain skipping"]
        correct_index: 0
        points: 1
        time_limit: 20

  - number: 2
    questions:
      - text: "What is ‘zero-shot prompting’?"
        options: ["Training a model without data", "Providing multiple examples", "Using reinforcement learning", "Asking the model to perform a task without examples"]
        correct_index: 3
        points: 1
        time_limit: 20

      - text: "Which practice helps ensure consistent formatting in AI outputs?"
        options: ["Leaving format open-ended", "Using shorter prompts", "Defining the desired output structure in the prompt","Increasing model randomness"]
        correct_index: 2
        points: 1
        time_limit: 20

      - text: "What is 'chain-of-thought prompting' primarily used for?"
        options: ["Speeding up responses", "Encouraging step-by-step reasoning", "Summarizing documents", "Translating code"]
        correct_index: 1
        points: 1
        time_limit: 20

      - text: "What factor most affects how many tokens a prompt consumes?"
        options: ["Model version", "Prompt length", "Temperature", "API key"]
        correct_index: 1
        points: 1
        time_limit: 20

      - text: "What does 'RLHF' stand for in AI training?"
        options: ["Reinforcement Learning from Human Feedback", "Recursive Loop for Heuristic Fine-tuning", "Real Learning for Hyper Functions", "Random Logic Handling Framework"]
        correct_index: 0
        points: 1
        time_limit: 20

  - number: 3
    questions:
      - text: "What does it mean to 'ground' a model's output?"
        options: ["Shorten its response", "Increase randomness", "Limit temperature", "Connect it to reliable data sources"]
        correct_index: 3
        points: 1
        time_limit: 20

      - text: "What is one benefit of giving AI models role-based prompts (e.g., 'You are a data analyst')?"
        options: ["It increases randomness", "It decreases token usage", "It sets the context and tone for better responses", "It bypasses filters"]
        correct_index: 2
        points: 1
        time_limit: 20

      - text: "What’s a good practice when debugging prompt performance?"
        options: ["Make prompts longer without structure", "Test variations systematically", "Avoid reusing previous prompts", "Ignore model logs"]
        correct_index: 1
        points: 1
        time_limit: 20

      - text: "What is the advantage of giving step-by-step instructions?"
        options: ["The model predicts outcomes faster", "The model reasons more reliably", "It reduces token cost", "It disables randomness"]
        correct_index: 1
        points: 1
        time_limit: 20

      - text: "Why is temperature an important parameter in generation?"
        options: ["It controls the creativity vs. determinism of responses", "It increases API latency", "It affects training data", "It adjusts model speed"]
        correct_index: 0
        points: 1
        time_limit: 20


  # Optional: bonus round (not part of 1..3 rounds validation)
  - number: 4
    questions:
      - text: "What is the main drawback of a small context window?"
        options: ["Limited memory of earlier input", "Lower reasoning ability", "Increased cost", "Unstable responses"]
        correct_index: 0
        points: 1
        time_limit: 15

      - text: "Which model parameter controls randomness in outputs?"
        options: ["Max tokens", "Top-p",  "Temperature","Frequency penalty"]
        correct_index: 2
        points: 1
        time_limit: 15

      - text: "What is a 'system prompt' used for in chat-based models?"
        options: ["It trains the model", "It defines global behavior and tone", "It increases tokens", "It starts a new chat"]
        correct_index: 1
        points: 1
        time_limit: 15

  - number: 5
    questions:
      - text: "What is one best practice when giving examples in a prompt?"
        options: ["Ensure they match the desired style and format","Keep them irrelevant", "Add too many examples", "Use random cases"]
        correct_index: 0
        points: 1
        time_limit: 15

      - text: "How can you reduce token costs in an AI app?"
        options: ["Increase temperature", "Add detailed context", "Repeat instructions", "Use shorter, focused prompts"]
        correct_index: 3
        points: 1
        time_limit: 15

      - text: "What’s the role of an embedding model?"
        options: ["Generate creative text", "Convert text into numeric vectors for similarity search", "Improve tokenization", "Expand context window"]
        correct_index: 1
        points: 1
        time_limit: 15

  - number: 6
    questions:
      - text: "What does 'fine-tuning' do?"
        options: ["Improves inference speed", "Adapts a model to specific data or style", "Reduces model size", "Increases randomness"]
        correct_index: 1
        points: 1
        time_limit: 15

      - text: "What’s an example of a poor prompt?"
        options: ["Be detailed and specific", "Write code that might fix it", "Explain", "Tell me everything"]
        correct_index: 3
        points: 1
        time_limit: 15

      - text: "What’s a good strategy for improving model consistency?"
        options: ["Use structured templates", "Increase randomness", "Avoid examples", "Add irrelevant data"]
        correct_index: 0
        points: 1
        time_limit: 15



